# í•„ìš”í•œ ëª¨ë“ˆê³¼ ì‚¬ìš©ì ì •ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import lib.naverNewsCrawler as nnc       # ë‰´ìŠ¤ ê²€ìƒ‰ ë° ì €ì¥ ê¸°ëŠ¥
import lib.myTextMining as tm            # í˜•íƒœì†Œ ë¶„ì„, ë¹ˆë„ ë¶„ì„, ì‹œê°í™” ê¸°ëŠ¥
from konlpy.tag import Okt               # í˜•íƒœì†Œ ë¶„ì„ê¸° (Okt)

# ì‚¬ìš©ìë¡œë¶€í„° ê²€ìƒ‰ì–´ ì…ë ¥ë°›ê¸° (ì˜ˆ: ì¸ê³µì§€ëŠ¥)
keyword = input("ê²€ìƒ‰ì–´ : ").strip()

resultAll = []             # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê²°ê³¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
start = 1                  # ê²€ìƒ‰ ì‹œì‘ ìœ„ì¹˜
display = 10               # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ìˆ˜
resultJSON = nnc.searchNaverNews(keyword, start, display)  # ì²« ìš”ì²­

# ìµœëŒ€ 1000ê°œê¹Œì§€ ë°˜ë³µí•´ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
while (resultJSON is not None) and (resultJSON['display'] > 0) and (start <= 1000):
    nnc.setNewsSearchResult(resultAll, resultJSON)  # ë‰´ìŠ¤ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥

    start += resultJSON['display']  # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
    if start > 1000:
        break  # 1000ê°œ ë„˜ìœ¼ë©´ ì¢…ë£Œ

    resultJSON = nnc.searchNaverNews(keyword, start, display)  # ë‹¤ìŒ ë‰´ìŠ¤ ìš”ì²­

    # ìš”ì²­ ê²°ê³¼ ìƒíƒœ ì¶œë ¥
    if resultJSON is not None:
        print(f"{keyword} [{start}] : Search Request Success")
    else:
        print(f"{keyword} [{start}] : Error ~~~~")

# 3. CSV ì €ì¥
filename = f"./data/{keyword}_naver_news.csv"  # ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
nnc.saveSearchResult_CSV(resultAll, filename)  # íŒŒì¼ ì €ì¥

# 4. CSV ë¶ˆëŸ¬ì˜¤ê¸°
corpus_list = tm.load_corpus_from_csv(filename, "description")  # 'description' ì»¬ëŸ¼ í…ìŠ¤íŠ¸ë§Œ ë¶ˆëŸ¬ì˜´
print("ğŸ”¹ ìƒìœ„ 10ê°œ ë‰´ìŠ¤ ì„¤ëª…:")
print(corpus_list[:10])  # ì• 10ê°œë§Œ í™•ì¸

# 5. í˜•íƒœì†Œ ë¶„ì„ê¸° ì„¤ì •
my_tokenizer = Okt().pos                     # í˜•íƒœì†Œ ë¶„ì„ê¸°: POS íƒœê¹… í¬í•¨
my_tags = ['Noun', 'Adjective', 'Verb']      # ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì‚¬ìš©
my_stopwords = ['í•˜ë©°', 'ì…', 'í•˜ê³ ', 'ë¡œì¨', 'í•˜ì—¬', 'ì• ', 'ì œ', 'í•œë‹¤', 'ê·¸', 'ì´', 'í• ', 'ì •', 'ìˆ˜']  # ë¶ˆìš©ì–´

# 6. ë‹¨ì–´ ë¹ˆë„ ë¶„ì„
counter = tm.analyze_word_freq(corpus_list, my_tokenizer, my_tags, my_stopwords)  # ë¶„ì„ ìˆ˜í–‰
print("ğŸ”¹ ë‹¨ì–´ ë¹ˆë„ ìƒìœ„ 20ê°œ:")
print(list(counter.items())[:20])  # ìƒìœ„ 20ê°œ ì¶œë ¥

# 7. ì‹œê°í™”
tm.visualize_barchart(counter, "ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„", "ë¹ˆë„ìˆ˜", "í‚¤ì›Œë“œ")      # ìˆ˜í‰ ë§‰ëŒ€ ê·¸ë˜í”„
tm.visualize_wordcloud(counter) # ì›Œë“œí´ë¼ìš°ë“œ
