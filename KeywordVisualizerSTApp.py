#  í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import streamlit as st                    # ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ streamlit
import pandas as pd                      # ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ìš©
from konlpy.tag import Okt               # í˜•íƒœì†Œ ë¶„ì„ê¸°
from collections import Counter          # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°ìš©
import lib.naverNewsCrawler as nnc       # ë‰´ìŠ¤ ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬
import lib.myTextMining as tm            # í˜•íƒœì†Œ ë¶„ì„ ë° ë¹ˆë„ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬
import lib.STVisualizer as vis           # ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ (Streamlitìš©)

st.title(" í‚¤ì›Œë“œ ê¸°ë°˜ ë‰´ìŠ¤ ì‹œê°í™” ì•±")

# --- ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” ---
if 'data' not in st.session_state:
    st.session_state['data'] = None

# --- ì‚¬ì´ë“œë°” ì…ë ¥ ---
st.sidebar.header("íŒŒì¼ ì„ íƒ")
uploaded_file = st.sidebar.file_uploader("Drag and drop file here", type=["csv"])  # íŒŒì¼ ì—…ë¡œë“œ

st.sidebar.markdown("ë˜ëŠ”")
keyword = st.sidebar.text_input("ë‰´ìŠ¤ í‚¤ì›Œë“œ ê²€ìƒ‰")  # í‚¤ì›Œë“œ ì§ì ‘ ì…ë ¥

# --- ë‰´ìŠ¤ ê²€ìƒ‰ ì²˜ë¦¬ ---
if keyword and st.sidebar.button("ë‰´ìŠ¤ ê²€ìƒ‰"):
    resultAll = []
    start = 1
    display = 10
    resultJSON = nnc.searchNaverNews(keyword, start, display)

    while (resultJSON is not None) and (resultJSON['display'] > 0) and (start <= 1000):
        nnc.setNewsSearchResult(resultAll, resultJSON)     # ë‰´ìŠ¤ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
        start += resultJSON['display']
        if start > 1000:
            break
        resultJSON = nnc.searchNaverNews(keyword, start, display)

    data_df = pd.DataFrame(resultAll)  # ê²°ê³¼ DataFrameìœ¼ë¡œ ë³€í™˜
    nnc.saveSearchResult_CSV(resultAll, f"./data/{keyword}_naver_news.csv")  # CSV ì €ì¥
    st.session_state['data'] = data_df  # ì„¸ì…˜ì— ì €ì¥
    st.success(f"{keyword} ë‰´ìŠ¤ {len(data_df)}ê±´ ê²€ìƒ‰ ì™„ë£Œ")

# --- CSV íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ---
elif uploaded_file is not None:
    data_df = pd.read_csv(uploaded_file)
    st.session_state['data'] = data_df
    st.success(f"CSV íŒŒì¼ ë¡œë”© ì™„ë£Œ! ì´ {len(data_df)}ê°œ ë¬¸ì„œ")

# --- ë°ì´í„° í™•ì¸ ë° ë¶„ì„ ---
data = st.session_state['data']

if data is not None:
    col_name = st.text_input("ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” ì»¬ëŸ¼ëª…", value="description")

    if col_name in data.columns:
        corpus = list(data[col_name].dropna())  # ê²°ì¸¡ê°’ ì œê±°í•œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        st.sidebar.header("ì„¤ì •")

        show_bar = st.sidebar.checkbox("ğŸŒŸ ë¹ˆë„ìˆ˜ ê·¸ë˜í”„", value=True)
        bar_word_count = st.sidebar.slider("ë‹¨ì–´ ìˆ˜ (ê·¸ë˜í”„)", 10, 50, 20)

        show_cloud = st.sidebar.checkbox("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ", value=True)
        cloud_word_count = st.sidebar.slider("ë‹¨ì–´ ìˆ˜ (ì›Œë“œí´ë¼ìš°ë“œ)", 20, 500, 100)

        if st.sidebar.button("ë¶„ì„ ì‹œì‘"):
            tokenizer = Okt().pos  # í˜•íƒœì†Œ ë¶„ì„ê¸°
            tags = ['Noun', 'Adjective', 'Verb']  # ì‚¬ìš©í•  í’ˆì‚¬
            stopwords = ['í•˜ë©°', 'ì…', 'í•˜ê³ ', 'ë¡œì¨', 'í•˜ì—¬', 'ì• ', 'ì œ', 'í•œë‹¤', 'ê·¸', 'ì´', 'í• ', 'ì •', 'ìˆ˜']  # ë¶ˆìš©ì–´

            counter = tm.analyze_word_freq(corpus, tokenizer, tags, stopwords)

            if show_bar:
                vis.visualize_barchart(counter, "í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜", "ë¹ˆë„ìˆ˜", "ë‹¨ì–´", top_n=bar_word_count)

            if show_cloud:
                vis.visualize_wordcloud(counter, max_words=cloud_word_count)
    else:
        st.warning(f"âš ï¸ '{col_name}' ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ CSV ì—…ë¡œë“œ ë˜ëŠ” í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
